---
title: Least-Squares Regression
output:
  xaringan::moon_reader:
    css: "lab-slides.css"
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
editor_options: 
  chunk_output_type: console
---

### Agenda

.large[
* Major/minor declaration
* Recap regression
* Least squares
]

---

### Major/minor declaration

.large[
* January 31 -- February 4
* You may declare a major or minor in the Math and Stats dept. if you have *completed* 40 credit hours
* Open house opportunities for statistics:
  * Tuesday, February 1, 5:00pm-6:00pm In Person in Manchester 122
  * Wednesday, February 2, 4:00pm-5:00pm via Zoom
]

---

### Recap: regression

.large[
**Regression:** model the relationship between predictor $x$ and response $y$

**Regression model:** $y = f(x) + \varepsilon$

* $f$ = systematic information that $x$ provides about $y$
* $\varepsilon$ = random noise

**Linear regression:** $y = \beta_0 + \beta_1 x + \varepsilon$

]

---

### Recap: linear regression

.large[
**Observed data (sample):** Weight and wing length for 116 sparrows
]

```{r echo=F, message=F, warning=F, fig.align='center', fig.width=6, fig.height=4}
library(Stat2Data)
library(tidyverse)
data(Sparrows)

Sparrows %>%
  ggplot(aes(x = Weight, y = WingLength)) +
  geom_point(size=2.5) +
  labs(y = "Weight (g)", 
       x = "Wing Length (mm)") +
  theme_bw() +
  theme(text = element_text(size=25))
```

.large[
**Regression model (population):**

.center[
$\text{WingLength} = \beta_0 + \beta_1 \text{Weight} + \varepsilon$
]
]

---

### Recap: linear regression

```{r echo=F, message=F, warning=F, fig.align='center', fig.width=6, fig.height=4}
library(Stat2Data)
library(tidyverse)
data(Sparrows)

Sparrows %>%
  ggplot(aes(x = Weight, y = WingLength)) +
  geom_point(size=2.5) +
  labs(y = "Weight (g)", 
       x = "Wing Length (mm)") +
  theme_bw() +
  theme(text = element_text(size=25))
```

.large[

**Estimated regression line (from sample):**

.center[
$\widehat{\text{WingLength}} = 8.76 + 1.31 \ \text{Weight}$
]
]

.large[
* $\widehat{\beta}_0 = 8.76$
* $\widehat{\beta}_1 = 1.31$
]
    
---

### Recap: interpreting regression coefficients

.large[
.center[
$\widehat{\text{WingLength}} = 8.76 + 1.31 \ \text{Weight}$
]
]

.large[
**Interpreting $\widehat{\beta}_0$:** If weight = 0g, we predict a wing length of 8.76mm.

**Interpreting $\widehat{\beta}_1$:** An increase of 1g in weight is associated with an increase of 1.31mm, on average, in wing length
]

---

### Concept check

.large[
Interested in the relationship between mileage and price for used Honda Accords. We will use linear regression.

.pull-left[

```{r, echo=F, fig.align='center', fig.width=6, fig.height=4}
data("AccordPrice")
AccordPrice %>%
  ggplot(aes(x = Mileage, y = Price)) +
  geom_point(size=2.5) +
  labs(x = "Miles (in 1000's)",
       y = "Price (in $1000's)") +
  theme_bw() +
  theme(text = element_text(size=25))
```
]


.pull-right[
Write the population regression model:

.abox[
(A) $\text{price} = \beta_0 + \beta_1 \text{miles}$
]

.bbox[
(B) $\text{price} = \beta_0 + \beta_1 \text{miles} + \varepsilon$
]

.cbox[
(C) $\widehat{\text{price}} = \widehat{\beta}_0 + \widehat{\beta}_1 \text{miles}$
]

.dbox[
(D) $\widehat{\text{price}} = \widehat{\beta}_0 + \widehat{\beta}_1 \text{miles} + \varepsilon$
]

]
]

--

.large[
**Answer:** (B)
]

---

### Concept check

.large[
.pull-left[
**Fitted line:**

```{r, echo=F, fig.align='center', fig.width=6, fig.height=4, message=F}
AccordPrice %>%
  ggplot(aes(x = Mileage, y = Price)) +
  geom_point(size=2.5) +
  geom_smooth(se=F, method="lm") +
  labs(x = "Miles (in 1000's)",
       y = "Price (in $1000's)") +
  theme_bw() +
  theme(text = element_text(size=25))
```

$\widehat{\text{price}} = 20.81 - 0.12 \ \text{miles}$

]


.pull-right[
Interpret the estimated <ins>intercept</ins>:

.abox[
(A) The estimated mileage for a car which costs $0 is 20,810 miles
]

.bbox[
(B) The intercept cannot be interpreted in this situation
]

.cbox[
(C) The estimated price for a car with 0 miles is $20,810
]

.dbox[
(D) Every additional 1000 miles on the car is associated with a decrease of $120 in price
]

]
]

--

.large[
**Answer:** (C)
]

---

### Concept check

.large[
**Fitted line:** $\widehat{\text{price}} = 20.81 - 0.12 \ \text{miles}$

Interpret the estimated <ins>slope</ins>:

.abox[
(A) Every additional 1000 miles on the car is associated with an increase of $120 in price, on average
]

.bbox[
(B) Driving another 1000 miles causes the car to increase $120 in price
]

.cbox[
(C) Driving another 1000 miles causes the car to decrease $120 in price
]

.dbox[
(D) Every additional 1000 miles on the car is associated with a decrease of $120 in price, on average
]

]


--

.large[
**Answer:** (D)
]

---

### Linear regression

```{r echo=F, message=F, fig.align='center', fig.width = 6, fig.height=4}
AccordPrice %>%
  ggplot(aes(x = Mileage, y = Price)) +
  geom_point(size=2.5) +
  geom_smooth(se=F, method="lm") +
  labs(x = "Miles (in 1000's)",
       y = "Price (in $1000's)") +
  theme_bw() +
  theme(text = element_text(size=25))
```

.large[
**Estimated line** (from sample): $\widehat{\text{price}} = 20.81 - 0.12 \ \text{miles}$

How do we calculate $\widehat{\beta}_0$ and $\widehat{\beta}_1$?
]

---

### Choosing between different lines

```{r echo=F, message=F, fig.align='center', fig.width = 12, fig.height=4}
library(patchwork)
p1 <- AccordPrice %>%
  ggplot(aes(x = Mileage, y = Price)) +
  geom_point(size=2.5) +
  geom_abline(slope = -0.1, intercept = 27, color = "blue",
              lwd = 1.5) +
  labs(x = "Miles (in 1000's)",
       y = "Price (in $1000's)") +
  theme_bw() +
  theme(text = element_text(size=25))

p2 <- AccordPrice %>%
  ggplot(aes(x = Mileage, y = Price)) +
  geom_point(size=2.5) +
  geom_abline(slope = -0.1, intercept = 20, color = "blue",
              lwd = 1.5) +
  labs(x = "Miles (in 1000's)",
       y = "Price (in $1000's)") +
  theme_bw() +
  theme(text = element_text(size=25))

p3 <- AccordPrice %>%
  ggplot(aes(x = Mileage, y = Price)) +
  geom_point(size=2.5) +
  geom_abline(slope = -0.02, intercept = 15, color = "blue",
              lwd = 1.5) +
  labs(x = "Miles (in 1000's)",
       y = "Price (in $1000's)") +
  theme_bw() +
  theme(text = element_text(size=25))

p1 + p2 + p3
```

.large[
.question[
Which one looks like the best choice?
]
]

--

.large[
Intuitively, want the line to "go through" the points. Can we formalize this?
]

---

### Residuals

```{r echo=F, message=F, fig.align='center', fig.width = 6, fig.height=4}
AccordPrice %>%
  ggplot(aes(x = Mileage, y = Price)) +
  geom_segment(aes(xend = Mileage,
                   yend = 20 - 0.1*Mileage),
               color = "red",
               lwd=1.5) +
  geom_point(size=2.5) +
  geom_abline(slope = -0.1, intercept = 20, color = "blue",
              lwd = 1.5) +
  labs(x = "Miles", 
       y = "Price") +
  theme_bw() +
  theme(text = element_text(size=25))
```

.large[

**Data:** $(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)$, where $n$ = number of observations

* E.g., $(\text{mileage}_1, \text{price}_1), ..., (\text{mileage}_{30}, \text{price}_{30})$

]

---

### Residuals

```{r echo=F, message=F, fig.align='center', fig.width = 6, fig.height=4}
AccordPrice %>%
  ggplot(aes(x = Mileage, y = Price)) +
  geom_segment(aes(xend = Mileage,
                   yend = 20 - 0.1*Mileage),
               color = "red",
               lwd=1.5) +
  geom_point(size=2.5) +
  geom_abline(slope = -0.1, intercept = 20, color = "blue",
              lwd = 1.5) +
  labs(x = "Miles", 
       y = "Price") +
  theme_bw() +
  theme(text = element_text(size=25))
```

.large[

**Data:** $(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)$, where $n$ = number of observations

**Predictions:** $\widehat{y}_i = \widehat{\beta}_0 + \widehat{\beta}_1 x_i$ (prediction for $i$th observation)

**Residuals:** $e_i = y_i - \widehat{y}_i$ (difference between observed and predicted values)

]

---

### Residuals

```{r echo=F, message=F, fig.align='center', fig.width = 12, fig.height=4}
p1 <- AccordPrice %>%
  ggplot(aes(x = Mileage, y = Price)) +
  geom_segment(aes(xend = Mileage,
                   yend = 27 - 0.1*Mileage),
               color = "red",
               lwd=1.5) +
  geom_point(size=2.5) +
  geom_abline(slope = -0.1, intercept = 27, color = "blue",
              lwd = 1.5) +
  labs(x = "Miles", 
       y = "Price") +
  theme_bw() +
  theme(text = element_text(size=25))

p2 <- AccordPrice %>%
  ggplot(aes(x = Mileage, y = Price)) +
  geom_segment(aes(xend = Mileage,
                   yend = 20 - 0.1*Mileage),
               color = "red",
               lwd=1.5) +
  geom_point(size=2.5) +
  geom_abline(slope = -0.1, intercept = 20, color = "blue",
              lwd = 1.5) +
  labs(x = "Miles", 
       y = "Price") +
  theme_bw() +
  theme(text = element_text(size=25))

p3 <- AccordPrice %>%
  ggplot(aes(x = Mileage, y = Price)) +
  geom_segment(aes(xend = Mileage,
                   yend = 15 - 0.02*Mileage),
               color = "red",
               lwd=1.5) +
  geom_point(size=2.5) +
  geom_abline(slope = -0.02, intercept = 15, color = "blue",
              lwd = 1.5) +
  labs(x = "Miles", 
       y = "Price") +
  theme_bw() +
  theme(text = element_text(size=25))

p1 + p2 + p3
```

.large[
.question[
Want residuals to generally be small. How can we formalize this?
]
]

---

### Sum of the squared residuals
               
```{r echo=F, message=F, fig.align='center', fig.width = 12, fig.height=3}
p1 <- AccordPrice %>%
  mutate(fitted = 27 - 0.1*Mileage) %>%
  ggplot(aes(x = Mileage, y = Price)) +
  geom_rect(aes(xmin = Mileage, 
                xmax = Mileage + Price - fitted,
                ymin = Price, ymax = fitted), 
            fill = "red", color = "red", alpha = 0.2) +
  geom_point(size=2.5) +
  geom_abline(slope = -0.1, intercept = 27, color = "blue",
              lwd = 1.5) +
  labs(x = "Miles", 
       y = "Price",
       title = "SSE = 1871.17") +
  theme_bw() +
  theme(text = element_text(size=25))

p2 <- AccordPrice %>%
  mutate(fitted = 20 - 0.1*Mileage) %>%
  ggplot(aes(x = Mileage, y = Price)) +
  geom_rect(aes(xmin = Mileage, 
                xmax = Mileage + Price - fitted,
                ymin = Price, ymax = fitted), 
            fill = "red", color = "red", alpha = 0.2) +
  geom_point(size=2.5) +
  geom_abline(slope = -0.1, intercept = 20, color = "blue",
              lwd = 1.5) +
  labs(x = "Miles", 
       y = "Price",
       title = "SSE = 287.49") +
  theme_bw() +
  theme(text = element_text(size=25))

p3 <- AccordPrice %>%
  mutate(fitted = 15 - 0.02*Mileage) %>%
  ggplot(aes(x = Mileage, y = Price)) +
  geom_rect(aes(xmin = Mileage, 
                xmax = Mileage + Price - fitted,
                ymin = Price, ymax = fitted), 
            fill = "red", color = "red", alpha = 0.2) +
  geom_point(size=2.5) +
  geom_abline(slope = -0.02, intercept = 15, color = "blue",
              lwd = 1.5) +
  labs(x = "Miles", 
       y = "Price",
       title = "SSE = 747.78") +
  theme_bw() +
  theme(text = element_text(size=25))

p1 + p2 + p3
```

.large[
Sum of squared residuals (SSE) = $\sum_{i=1}^n (y_i - \widehat{y}_i)^2$
]

---

### Least Squares

```{r echo=F, message=F, fig.align='center', fig.width = 12, fig.height=3}
p1 <- AccordPrice %>%
  mutate(fitted = 27 - 0.1*Mileage) %>%
  ggplot(aes(x = Mileage, y = Price)) +
  geom_rect(aes(xmin = Mileage, 
                xmax = Mileage + Price - fitted,
                ymin = Price, ymax = fitted), 
            fill = "red", color = "red", alpha = 0.2) +
  geom_point(size=2.5) +
  geom_abline(slope = -0.1, intercept = 27, color = "blue",
              lwd = 1.5) +
  labs(x = "Miles", 
       y = "Price",
       title = "SSE = 1871.17") +
  theme_bw() +
  theme(text = element_text(size=25))

p2 <- AccordPrice %>%
  mutate(fitted = 20 - 0.1*Mileage) %>%
  ggplot(aes(x = Mileage, y = Price)) +
  geom_rect(aes(xmin = Mileage, 
                xmax = Mileage + Price - fitted,
                ymin = Price, ymax = fitted), 
            fill = "red", color = "red", alpha = 0.2) +
  geom_point(size=2.5) +
  geom_abline(slope = -0.1, intercept = 20, color = "blue",
              lwd = 1.5) +
  labs(x = "Miles", 
       y = "Price",
       title = "SSE = 287.49") +
  theme_bw() +
  theme(text = element_text(size=25))

p3 <- AccordPrice %>%
  mutate(fitted = 15 - 0.02*Mileage) %>%
  ggplot(aes(x = Mileage, y = Price)) +
  geom_rect(aes(xmin = Mileage, 
                xmax = Mileage + Price - fitted,
                ymin = Price, ymax = fitted), 
            fill = "red", color = "red", alpha = 0.2) +
  geom_point(size=2.5) +
  geom_abline(slope = -0.02, intercept = 15, color = "blue",
              lwd = 1.5) +
  labs(x = "Miles", 
       y = "Price",
       title = "SSE = 747.78") +
  theme_bw() +
  theme(text = element_text(size=25))

p1 + p2 + p3
```

.large[
Sum of squared residuals (SSE) = $\sum_{i=1}^n (y_i - \widehat{y}_i)^2 = \sum_{i=1}^n (y_i - \widehat{\beta}_0 - \widehat{\beta}_1 x_i)^2$

Choose $\widehat{\beta}_0$, $\widehat{\beta}_1$ to minimize SSE.
]

---

### Class activity, Part I

.large[
Spend a few minutes trying out different potential values for the estimated slope and intercept. 

[https://sta112-s22.github.io/class_activities/ca_lecture_8.html](https://sta112-s22.github.io/class_activities/ca_lecture_8.html)
]

---

### Fitting linear regression in R

```{r echo=F, fig.width=6, fig.height=4, fig.align='center'}
AccordPrice %>%
  ggplot(aes(x = Mileage, y = Price)) +
  geom_point(size=2.5) +
  labs(x = "Miles", 
       y = "Price") +
  theme_bw() +
  theme(text = element_text(size=25))
```

.large[
```r
lm(Price ~ Mileage, data = AccordPrice)
```
]

--

.large[
* `lm`: function used for regression ("linear model")
* `Price`: response variable
* `Mileage`: predictor
]

---

### Fitting linear regression in R

.large[
```{r}
lm(Price ~ Mileage, data = AccordPrice)
```

* $\widehat{\beta}_0 = 20.81$
* $\widehat{\beta}_1 = -0.12$
]

---

### Class activity, Part II

.large[
[https://sta112-s22.github.io/class_activities/ca_lecture_8.html](https://sta112-s22.github.io/class_activities/ca_lecture_8.html)
]

---

### Calculating $\widehat{\beta}_0$ and $\widehat{\beta}_1$

.large[
.center[
$SSE = \sum_{i=1}^n (y_i - \widehat{\beta}_0 - \widehat{\beta}_1 x_i)^2$
]
]

.large[
Choose $\widehat{\beta}_0$, $\widehat{\beta}_1$ to minimize SSE

* Option 1: search for $\widehat{\beta}_0$, $\widehat{\beta}_1$ like in class activity Part I
]
--
.large[

    * not efficient
    * not what R does
]
--
.large[
* Option 2: closed-form equation?
]

---

### Equations for $\widehat{\beta}_0$ and $\widehat{\beta}_1$

.large[
.center[
$\widehat{\beta}_1 = \dfrac{\sum_{i=1}^n (x_i - \overline{x})(y_i - \overline{y})}{\sum_{i=1}^n (x_i - \overline{x})^2}$

$\widehat{\beta}_0 = \overline{y} - \widehat{\beta}_1 \overline{x}$
]
]

.large[
where 

.center[
$\overline{x} = \frac{1}{n} \sum_{i=1}^n x_i$

$\overline{y} = \frac{1}{n} \sum_{i=1}^n y_i$
]
]

---

### When should I fit a linear model?

.large[
**Shape assumption:** the shape of the regression model is at least approximately correct
]

--

.large[
Linear regression model:

.center[
$y = \beta_0 + \beta_1 x + \varepsilon$
]
]

.large[
When using linear regression, the shape assumption is that the relationship is (at least approximately) linear.

.pull-left[
```{r, echo=F, fig.align='center', fig.width=6, fig.height=3.7}
data.frame(x = 1:100,
           y = 1:100 + rnorm(100, sd=20)) %>%
  ggplot(aes(x = x, y = y)) +
  geom_point(size=2) +
  labs(title = "Relationship could be linear") +
  theme_bw() +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        text = element_text(size=25))
```
]

.pull-right[
```{r, echo=F, fig.align='center', fig.width=6, fig.height=3.7}
data.frame(x = 1:100,
           y = log(10*(1:100)) + rnorm(100, sd=0.3)) %>%
  ggplot(aes(x = x, y = y)) +
  geom_point(size=2) +
  labs(title = "Relationship not linear") +
  theme_bw() +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        text = element_text(size=25))
```
]
]

---

### Assessing shape: residual plots

.large[
**Residual plot:** plot residuals $y - \widehat{y}$ on vertical axis, and predicted values $\widehat{y}$ on horizontal axis. Add a horizontal line at 0.
]

```{r, echo = F, message=F, fig.align='center', fig.width=6, fig.height=4}
library(latex2exp)
data.frame(x = 1:100,
           y = rnorm(100, sd=20)) %>%
  ggplot(aes(x = x, y = y)) +
  geom_point(size=2) +
  geom_abline(slope = 0, intercept = 0,
              color = "blue", lwd=1.2) +
  labs(title = "Residual plot",
       x = TeX("$\\widehat{y}$"),
       y = TeX("$y - \\widehat{y}$")) +
  theme_bw() +
  theme(text = element_text(size=25))
```

---

### Residual plots

```{r, echo = F, message=F, fig.align='center', fig.width=6, fig.height=4}
data.frame(x = 1:100,
           y = rnorm(100, sd=20)) %>%
  ggplot(aes(x = x, y = y)) +
  geom_point(size=2) +
  geom_abline(slope = 0, intercept = 0,
              color = "blue", lwd=1.2) +
  labs(title = "Residual plot",
       x = TeX("$\\widehat{y}$"),
       y = TeX("$y - \\widehat{y}$")) +
  theme_bw() +
  theme(text = element_text(size=25))
```

.large[
Shape assumption is reasonable if: 
* residuals appear to be scattered randomly above and below 0
* no clear patterns in the residuals
]

---

### Concept check

.pull-left[
```{r, echo = F, message=F, fig.align='center', fig.width=6, fig.height=6}
data.frame(x = 1:100,
           y = rnorm(100, sd=20)*(1:100)*0.02) %>%
  ggplot(aes(x = x, y = y)) +
  geom_point(size=2) +
  geom_abline(slope = 0, intercept = 0,
              color = "blue", lwd=1.2) +
  labs(title = "Residual plot",
       x = TeX("$\\widehat{y}$"),
       y = TeX("$y - \\widehat{y}$")) +
  theme_bw() +
  theme(text = element_text(size=25))
```
]

.large[
.pull-right[
Does the shape assumption look reasonable?

.abox[
(A) Yes
]

.bbox[
(B) No
]

]
]

--

.large[
**Answer:** (A) Yes (residuals randomly scattered above and below 0)
]

---

### Concept check

.pull-left[
```{r, echo = F, message=F, fig.align='center', fig.width=6, fig.height=6}
sim_dat <- data.frame(x = seq(-50, 50),
           y = 0.02*seq(-50, 50)^2 + rnorm(101, sd=10)*(1:101)*0.02)
sim_reg <- lm(y ~ x, data = sim_dat)

data.frame(pred = sim_reg$fitted.values,
           res = sim_reg$residuals) %>%
  ggplot(aes(x = pred, y = res)) +
  geom_point(size=2) +
  geom_abline(slope = 0, intercept = 0,
              color = "blue", lwd=1.2) +
  labs(title = "Residual plot",
       x = TeX("$\\widehat{y}$"),
       y = TeX("$y - \\widehat{y}$")) +
  theme_bw() +
  theme(text = element_text(size=25))
```
]

.large[
.pull-right[
Does the shape assumption look reasonable?

.abox[
(A) Yes
]

.bbox[
(B) No
]

]
]

--

.large[
**Answer:** (B) No
]

---

## Concept check

.pull-left[
```{r, echo = F, message=F, fig.align='center', fig.width=6, fig.height=6}
sim_dat <- data.frame(x = seq(-50, 50),
           y = -0.02*seq(-50, 50)^2 + rnorm(101, sd=10))
sim_reg <- lm(y ~ x, data = sim_dat)

data.frame(pred = sim_reg$fitted.values,
           res = sim_reg$residuals) %>%
  ggplot(aes(x = pred, y = res)) +
  geom_point(size=2) +
  geom_abline(slope = 0, intercept = 0,
              color = "blue", lwd=1.2) +
  labs(title = "Residual plot",
       x = TeX("$\\widehat{y}$"),
       y = TeX("$y - \\widehat{y}$")) +
  theme_bw() +
  theme(text = element_text(size=25))
```
]

.large[
.pull-right[
Does the shape assumption look reasonable?

.abox[
(A) Yes
]

.bbox[
(B) No
]

]
]

--

.large[
**Answer:** (B) No
]

---

## Concept check

.pull-left[
```{r, echo = F, message=F, fig.align='center', fig.width=6, fig.height=6}
set.seed(4)
x <- seq(0, 10, 0.1)
y <- seq(0, 10, 0.1)^1.3 + rnorm(101, sd=3)
fitted <- lm(y~x)$fitted
resids <- lm(y~x)$residuals
data.frame(x = fitted,
           y = resids) %>%
  ggplot(aes(x = x, y = y)) +
  geom_point(size=2) +
  geom_abline(slope = 0, intercept = 0,
              color = "blue", lwd=1.2) +
  labs(title = "Residual plot",
       x = TeX("$\\widehat{y}$"),
       y = TeX("$y - \\widehat{y}$")) +
  theme_bw() +
  theme(text = element_text(size=25))
```
]

.large[
.pull-right[
Does the shape assumption look reasonable?

.abox[
(A) Yes
]

.bbox[
(B) No
]

]
]

--

.large[
**Answer:** (A) Yes -- not perfect, but close enough
]